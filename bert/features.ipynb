{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YZY/opt/anaconda3/envs/pytorch_cpu/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from mlp import mlp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import InputExample, InputFeatures\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer, BertModel\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "config=BertConfig.from_pretrained('./model')\n",
    "tokenizer=BertTokenizer.from_pretrained('./model')\n",
    "model=BertModel.from_pretrained('./model',config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(lines, set_type):\n",
    "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "    examples = []\n",
    "    del lines[0]\n",
    "    for (i, line) in enumerate(lines):\n",
    "        guid = \"%s-%s\" % (set_type, i)\n",
    "        # label = int(line[1])\n",
    "        # in available.csv ,text is put at col:1,and don't need to be replaced with YZYHUST\n",
    "        # text_a = line[2].replace(\"YZYHUST\", ',')\n",
    "        text_a=line[1]\n",
    "        examples.append(\n",
    "            InputExample(guid=guid, text_a=text_a, text_b=None, label=None))\n",
    "    return examples\n",
    "\n",
    "def Load_data(tokenizer,file_path):\n",
    "    csv.field_size_limit(500 * 1024 * 1024)\n",
    "    with open(file_path, 'r') as f:\n",
    "        examples = create_examples(list(csv.reader(f)), 'predict')\n",
    "    label_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    features = convert_examples_to_features(\n",
    "        examples,\n",
    "        tokenizer,\n",
    "        label_list=label_list,\n",
    "        max_length=256,\n",
    "        output_mode=\"classification\",\n",
    "    )\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features],\n",
    "                                 dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features],\n",
    "                                      dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features],\n",
    "                                      dtype=torch.long)\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask,\n",
    "                            all_token_type_ids)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YZY/opt/anaconda3/envs/pytorch_cpu/lib/python3.10/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "file_path='./url/ip/ip_test.csv'\n",
    "pred_dataloader = Load_data(tokenizer,file_path=file_path)\n",
    "file=pd.read_csv(file_path)\n",
    "label=file['label']\n",
    "label.to_csv('./url/ip/test_label.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn((3,2))\n",
    "a=a.unsqueeze(0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "feature_list=[]\n",
    "batch=pred_dataloader[0]\n",
    "model.eval()\n",
    "batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {\n",
    "        'input_ids': batch[0].unsqueeze(0),\n",
    "        'attention_mask': batch[1].unsqueeze(0),\n",
    "        'token_type_ids':batch[2].unsqueeze(0)\n",
    "    }\n",
    "    _,pool_outputs = model(**inputs,return_dict=False)\n",
    "    print(pool_outputs.squeeze().shape)\n",
    "    feature_list.append(pool_outputs)\n",
    "features=torch.concat(feature_list,dim=0)\n",
    "torch.save(features,'./url/ip/features_test.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å±‚æ¬¡åˆ†ç±»å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "class hierarchy_cls():\n",
    "    def __init__(self,use_ip=False) -> None:\n",
    "        if use_ip==False:\n",
    "            self.mlp=mlp(in_features=775)\n",
    "            st=torch.load('./classifier_model/best_mlp.pkl')\n",
    "            self.mlp.load_state_dict(st)\n",
    "            self.LR24=joblib.load('./classifier_model/LR24.pkl')\n",
    "            self.LR26=joblib.load('./classifier_model/LR26.pkl')\n",
    "            self.LR48=joblib.load('./classifier_model/LR48.pkl')\n",
    "        else:\n",
    "            self.mlp=mlp(in_features=778)\n",
    "            st=torch.load('./classifier_model/best_mlp_ip.pkl')\n",
    "            self.mlp.load_state_dict(st)\n",
    "            self.LR24=joblib.load('./classifier_model/LR24_ip.pkl')\n",
    "            self.LR26=joblib.load('./classifier_model/LR26_ip.pkl')\n",
    "            self.LR48=joblib.load('./classifier_model/LR48_ip.pkl')\n",
    "    def predict(self,x):\n",
    "        output=first_division=(torch.argmax(self.mlp(x),dim=-1)).numpy()\n",
    "        idx_gp2=first_division==2\n",
    "        # print(x.shape)\n",
    "        features_2=x[idx_gp2]\n",
    "\n",
    "        if features_2.shape[0]:\n",
    "            second_division=self.LR24.predict(features_2)\n",
    "            idx_gp26=second_division==2\n",
    "            idx_gp48=second_division==4\n",
    "            ft_26=features_2[idx_gp26]\n",
    "            ft_48=features_2[idx_gp48]\n",
    "            gp2=output[idx_gp2]\n",
    "            if ft_26.shape[0]:\n",
    "                pred_26=self.LR26.predict(ft_26)\n",
    "                gp2[idx_gp26]=pred_26\n",
    "            if ft_48.shape[0]:\n",
    "                pred_48=self.LR48.predict(ft_48)\n",
    "                gp2[idx_gp48]=pred_48\n",
    "        \n",
    "            output[idx_gp2]=gp2\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‹¼æŽ¥ç‰¹å¾(text+URL+IP)ï¼Œè¿›è¡Œæœ€åŽçš„é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset used to preprocess data\n",
    "#TODO:use or not use ip feature\n",
    "from torch.utils.data import Dataset\n",
    "class url_data(Dataset):\n",
    "    def __init__(self,file_name,use_ip=True) -> None:\n",
    "        super().__init__()\n",
    "        self.file=pd.read_csv(file_name)\n",
    "        self.text_data=Load_data(tokenizer,file_path=file_name)\n",
    "        self.use_ip=use_ip\n",
    "    def __getitem__(self, index):\n",
    "        batch=self.text_data[index]\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                'input_ids': batch[0].unsqueeze(0),\n",
    "                'attention_mask': batch[1].unsqueeze(0),\n",
    "                'token_type_ids':batch[2].unsqueeze(0)\n",
    "            }\n",
    "            _,pool_outputs = model(**inputs,return_dict=False)\n",
    "            text_feature=pool_outputs.squeeze()\n",
    "        if self.use_ip:\n",
    "            ip_feature=torch.tensor(self.file.iloc[index,3:6].to_numpy(dtype=float))\n",
    "        url_feature=torch.tensor(self.file.iloc[index,6:].to_numpy(dtype=float))\n",
    "        if self.use_ip:\n",
    "            feature=torch.concat([text_feature,url_feature,ip_feature],dim=-1)\n",
    "        else:\n",
    "            feature=torch.concat([text_feature,url_feature],dim=-1)\n",
    "        url=self.file.iloc[index,0]\n",
    "        return url,feature\n",
    "    def __len__(self):\n",
    "        return len(self.file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YZY/opt/anaconda3/envs/pytorch_cpu/lib/python3.10/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test=url_data(file_name='./test/no_ip.csv',use_ip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:43<00:00,  7.29s/it]\n"
     ]
    }
   ],
   "source": [
    "data=DataLoader(test,batch_size=32)\n",
    "cls=hierarchy_cls(use_ip=False)\n",
    "url,ft=test[0]\n",
    "url_col=[]\n",
    "label=[]\n",
    "for url,ft in tqdm(data):\n",
    "    url_col+=list(url)\n",
    "    pred=cls.predict(torch.tensor(ft.numpy(),dtype=torch.float))\n",
    "    label+=list(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_csv=pd.Series(url_col)\n",
    "label_csv=pd.Series(label)\n",
    "prediction=pd.concat([url_csv,label_csv],axis=1)\n",
    "prediction.columns=['url','label']\n",
    "prediction.to_csv('./final_text_noip_prediction.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    73\n",
       "2     56\n",
       "6     31\n",
       "11     8\n",
       "4      7\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp=pd.read_csv('./prediction/final_text_noip_prediction.csv')\n",
    "fp['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
