{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----依赖项加载完毕-----\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from mlp import mlp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import InputExample, InputFeatures\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer, BertModel\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "print(\"-----依赖项加载完毕-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----BERT model加载完毕-----\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "config=BertConfig.from_pretrained('./model')\n",
    "tokenizer=BertTokenizer.from_pretrained('./model')\n",
    "model=BertModel.from_pretrained('./model',config=config)\n",
    "print(\"-----BERT model加载完毕-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----数据处理函数加载完毕-----\n"
     ]
    }
   ],
   "source": [
    "def create_examples(lines, set_type):\n",
    "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "    examples = []\n",
    "    del lines[0]\n",
    "    for (i, line) in enumerate(lines):\n",
    "        guid = \"%s-%s\" % (set_type, i)\n",
    "        # label = int(line[1])\n",
    "        # in available.csv ,text is put at col:1,and don't need to be replaced with YZYHUST\n",
    "        # text_a = line[2].replace(\"YZYHUST\", ',')\n",
    "        # !!!attention\n",
    "        text_a=line[1]\n",
    "        examples.append(\n",
    "            InputExample(guid=guid, text_a=text_a, text_b=None, label=None))\n",
    "    return examples\n",
    "\n",
    "def Load_data(tokenizer,file_path):\n",
    "    csv.field_size_limit(500 * 1024 * 1024)\n",
    "    with open(file_path, 'r') as f:\n",
    "        examples = create_examples(list(csv.reader(f)), 'predict')\n",
    "    label_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    features = convert_examples_to_features(\n",
    "        examples,\n",
    "        tokenizer,\n",
    "        label_list=label_list,\n",
    "        max_length=256,\n",
    "        output_mode=\"classification\",\n",
    "    )\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features],\n",
    "                                 dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features],\n",
    "                                      dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features],\n",
    "                                      dtype=torch.long)\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask,\n",
    "                            all_token_type_ids)\n",
    "    # return DataLoader(dataset,batch_size=32)\n",
    "    return dataset\n",
    "\n",
    "print(\"-----数据处理函数加载完毕-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----数据加载完毕-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YZY/opt/anaconda3/envs/pytorch_cpu/lib/python3.10/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "file_path='./url/ip/ip_display.csv'\n",
    "pred_dataloader = Load_data(tokenizer,file_path=file_path)\n",
    "file=pd.read_csv(file_path)\n",
    "label=file['label']\n",
    "label.to_csv('./test_label_display.csv',index=None)\n",
    "print(\"-----数据加载完毕-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----开始抽取文本特征-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----文本特征抽取完毕-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 抽取文本特征\n",
    "feature_list=[]\n",
    "\n",
    "print(\"-----开始抽取文本特征-----\")\n",
    "for batch in tqdm(pred_dataloader):\n",
    "    model.eval()\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'token_type_ids':batch[2]\n",
    "        }\n",
    "        _,pool_outputs = model(**inputs,return_dict=False)\n",
    "        feature_list.append(pool_outputs)\n",
    "features=torch.concat(feature_list,dim=0)\n",
    "torch.save(features,'./features_display.pt')\n",
    "\n",
    "print(\"-----文本特征抽取完毕-----\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 层次分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----分类器加载完毕-----\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "class hierarchy_cls():\n",
    "    def __init__(self,use_ip=False) -> None:\n",
    "        if use_ip==False:\n",
    "            self.mlp=mlp(in_features=775)\n",
    "            st=torch.load('./classifier_model/best_mlp.pkl')\n",
    "            self.mlp.load_state_dict(st)\n",
    "            self.LR24=joblib.load('./classifier_model/LR24.pkl')\n",
    "            self.LR26=joblib.load('./classifier_model/LR26.pkl')\n",
    "            self.LR48=joblib.load('./classifier_model/LR48.pkl')\n",
    "        else:\n",
    "            self.mlp=mlp(in_features=778)\n",
    "            st=torch.load('./classifier_model/best_mlp_ip.pkl')\n",
    "            self.mlp.load_state_dict(st)\n",
    "            self.LR24=joblib.load('./classifier_model/LR24_ip.pkl')\n",
    "            self.LR26=joblib.load('./classifier_model/LR26_ip.pkl')\n",
    "            self.LR48=joblib.load('./classifier_model/LR48_ip.pkl')\n",
    "    def predict(self,x):\n",
    "        output=first_division=(torch.argmax(self.mlp(x),dim=-1)).numpy()\n",
    "        idx_gp2=first_division==2\n",
    "        # print(x.shape)\n",
    "        features_2=x[idx_gp2]\n",
    "\n",
    "        if features_2.shape[0]:\n",
    "            second_division=self.LR24.predict(features_2)\n",
    "            idx_gp26=second_division==2\n",
    "            idx_gp48=second_division==4\n",
    "            ft_26=features_2[idx_gp26]\n",
    "            ft_48=features_2[idx_gp48]\n",
    "            gp2=output[idx_gp2]\n",
    "            if ft_26.shape[0]:\n",
    "                pred_26=self.LR26.predict(ft_26)\n",
    "                gp2[idx_gp26]=pred_26\n",
    "            if ft_48.shape[0]:\n",
    "                pred_48=self.LR48.predict(ft_48)\n",
    "                gp2[idx_gp48]=pred_48\n",
    "        \n",
    "            output[idx_gp2]=gp2\n",
    "\n",
    "        return output\n",
    "print(\"-----分类器加载完毕-----\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拼接特征(text+URL+IP)，进行最后的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----数据类加载完毕-----\n"
     ]
    }
   ],
   "source": [
    "# dataset used to preprocess data\n",
    "from torch.utils.data import Dataset\n",
    "class url_data(Dataset):\n",
    "    def __init__(self,file_name,use_ip=True) -> None:\n",
    "        super().__init__()\n",
    "        self.file=pd.read_csv(file_name)\n",
    "        self.text_data=Load_data(tokenizer,file_path=file_name)\n",
    "        self.use_ip=use_ip\n",
    "    def __getitem__(self, index):\n",
    "        batch=self.text_data[index]\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                'input_ids': batch[0].unsqueeze(0),\n",
    "                'attention_mask': batch[1].unsqueeze(0),\n",
    "                'token_type_ids':batch[2].unsqueeze(0)\n",
    "            }\n",
    "            _,pool_outputs = model(**inputs,return_dict=False)\n",
    "            text_feature=pool_outputs.squeeze()\n",
    "        if self.use_ip:\n",
    "            ip_feature=torch.tensor(self.file.iloc[index,3:6].to_numpy(dtype=float))\n",
    "        url_feature=torch.tensor(self.file.iloc[index,6:].to_numpy(dtype=float))\n",
    "        if self.use_ip:\n",
    "            feature=torch.concat([text_feature,url_feature,ip_feature],dim=-1)\n",
    "        else:\n",
    "            feature=torch.concat([text_feature,url_feature],dim=-1)\n",
    "        url=self.file.iloc[index,0]\n",
    "        return url,feature\n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "print(\"-----数据类加载完毕-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----数据加载完毕-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YZY/opt/anaconda3/envs/pytorch_cpu/lib/python3.10/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test=url_data(file_name='./test/ip_encode_display.csv',use_ip=True)\n",
    "print(\"-----数据加载完毕-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----数据预测完毕-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data=DataLoader(test,batch_size=32)\n",
    "cls=hierarchy_cls(use_ip=True)\n",
    "url,ft=test[0]\n",
    "url_col=[]\n",
    "label=[]\n",
    "for url,ft in tqdm(data):\n",
    "    url_col+=list(url)\n",
    "    pred=cls.predict(torch.tensor(ft.numpy(),dtype=torch.float))\n",
    "    label+=list(pred)\n",
    "    \n",
    "url_csv=pd.Series(url_col)\n",
    "label_csv=pd.Series(label)\n",
    "prediction=pd.concat([url_csv,label_csv],axis=1)\n",
    "prediction.columns=['url','label']\n",
    "prediction.to_csv('./prediction.csv',index=None)\n",
    "print(\"-----数据预测完毕-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
