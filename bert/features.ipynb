{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ä¾èµ–é¡¹åŠ è½½å®Œæ¯•-----\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from mlp import mlp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import InputExample, InputFeatures\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer, BertModel\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "print(\"-----ä¾èµ–é¡¹åŠ è½½å®Œæ¯•-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----BERT modelåŠ è½½å®Œæ¯•-----\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "config=BertConfig.from_pretrained('./model')\n",
    "tokenizer=BertTokenizer.from_pretrained('./model')\n",
    "model=BertModel.from_pretrained('./model',config=config)\n",
    "print(\"-----BERT modelåŠ è½½å®Œæ¯•-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----æ•°æ®å¤„ç†å‡½æ•°åŠ è½½å®Œæ¯•-----\n"
     ]
    }
   ],
   "source": [
    "def create_examples(lines, set_type):\n",
    "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "    examples = []\n",
    "    del lines[0]\n",
    "    for (i, line) in enumerate(lines):\n",
    "        guid = \"%s-%s\" % (set_type, i)\n",
    "        # label = int(line[1])\n",
    "        # in available.csv ,text is put at col:1,and don't need to be replaced with YZYHUST\n",
    "        # text_a = line[2].replace(\"YZYHUST\", ',')\n",
    "        # !!!attention\n",
    "        text_a=line[1]\n",
    "        examples.append(\n",
    "            InputExample(guid=guid, text_a=text_a, text_b=None, label=None))\n",
    "    return examples\n",
    "\n",
    "def Load_data(tokenizer,file_path):\n",
    "    csv.field_size_limit(500 * 1024 * 1024)\n",
    "    with open(file_path, 'r') as f:\n",
    "        examples = create_examples(list(csv.reader(f)), 'predict')\n",
    "    label_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    features = convert_examples_to_features(\n",
    "        examples,\n",
    "        tokenizer,\n",
    "        label_list=label_list,\n",
    "        max_length=256,\n",
    "        output_mode=\"classification\",\n",
    "    )\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features],\n",
    "                                 dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features],\n",
    "                                      dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features],\n",
    "                                      dtype=torch.long)\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask,\n",
    "                            all_token_type_ids)\n",
    "    # return DataLoader(dataset,batch_size=32)\n",
    "    return dataset\n",
    "\n",
    "print(\"-----æ•°æ®å¤„ç†å‡½æ•°åŠ è½½å®Œæ¯•-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----æ•°æ®åŠ è½½å®Œæ¯•-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YZY/opt/anaconda3/envs/pytorch_cpu/lib/python3.10/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "file_path='./url/ip/ip_display.csv'\n",
    "pred_dataloader = Load_data(tokenizer,file_path=file_path)\n",
    "file=pd.read_csv(file_path)\n",
    "label=file['label']\n",
    "label.to_csv('./test_label_display.csv',index=None)\n",
    "print(\"-----æ•°æ®åŠ è½½å®Œæ¯•-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----å¼€å§‹æŠ½å–æ–‡æœ¬ç‰¹å¾-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----æ–‡æœ¬ç‰¹å¾æŠ½å–å®Œæ¯•-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# æŠ½å–æ–‡æœ¬ç‰¹å¾\n",
    "feature_list=[]\n",
    "\n",
    "print(\"-----å¼€å§‹æŠ½å–æ–‡æœ¬ç‰¹å¾-----\")\n",
    "for batch in tqdm(pred_dataloader):\n",
    "    model.eval()\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'token_type_ids':batch[2]\n",
    "        }\n",
    "        _,pool_outputs = model(**inputs,return_dict=False)\n",
    "        feature_list.append(pool_outputs)\n",
    "features=torch.concat(feature_list,dim=0)\n",
    "torch.save(features,'./features_display.pt')\n",
    "\n",
    "print(\"-----æ–‡æœ¬ç‰¹å¾æŠ½å–å®Œæ¯•-----\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å±‚æ¬¡åˆ†ç±»å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----åˆ†ç±»å™¨åŠ è½½å®Œæ¯•-----\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "class hierarchy_cls():\n",
    "    def __init__(self,use_ip=False) -> None:\n",
    "        if use_ip==False:\n",
    "            self.mlp=mlp(in_features=775)\n",
    "            st=torch.load('./classifier_model/best_mlp.pkl')\n",
    "            self.mlp.load_state_dict(st)\n",
    "            self.LR24=joblib.load('./classifier_model/LR24.pkl')\n",
    "            self.LR26=joblib.load('./classifier_model/LR26.pkl')\n",
    "            self.LR48=joblib.load('./classifier_model/LR48.pkl')\n",
    "        else:\n",
    "            self.mlp=mlp(in_features=778)\n",
    "            st=torch.load('./classifier_model/best_mlp_ip.pkl')\n",
    "            self.mlp.load_state_dict(st)\n",
    "            self.LR24=joblib.load('./classifier_model/LR24_ip.pkl')\n",
    "            self.LR26=joblib.load('./classifier_model/LR26_ip.pkl')\n",
    "            self.LR48=joblib.load('./classifier_model/LR48_ip.pkl')\n",
    "    def predict(self,x):\n",
    "        output=first_division=(torch.argmax(self.mlp(x),dim=-1)).numpy()\n",
    "        idx_gp2=first_division==2\n",
    "        # print(x.shape)\n",
    "        features_2=x[idx_gp2]\n",
    "\n",
    "        if features_2.shape[0]:\n",
    "            second_division=self.LR24.predict(features_2)\n",
    "            idx_gp26=second_division==2\n",
    "            idx_gp48=second_division==4\n",
    "            ft_26=features_2[idx_gp26]\n",
    "            ft_48=features_2[idx_gp48]\n",
    "            gp2=output[idx_gp2]\n",
    "            if ft_26.shape[0]:\n",
    "                pred_26=self.LR26.predict(ft_26)\n",
    "                gp2[idx_gp26]=pred_26\n",
    "            if ft_48.shape[0]:\n",
    "                pred_48=self.LR48.predict(ft_48)\n",
    "                gp2[idx_gp48]=pred_48\n",
    "        \n",
    "            output[idx_gp2]=gp2\n",
    "\n",
    "        return output\n",
    "print(\"-----åˆ†ç±»å™¨åŠ è½½å®Œæ¯•-----\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‹¼æ¥ç‰¹å¾(text+URL+IP)ï¼Œè¿›è¡Œæœ€åçš„é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----æ•°æ®ç±»åŠ è½½å®Œæ¯•-----\n"
     ]
    }
   ],
   "source": [
    "# dataset used to preprocess data\n",
    "from torch.utils.data import Dataset\n",
    "class url_data(Dataset):\n",
    "    def __init__(self,file_name,use_ip=True) -> None:\n",
    "        super().__init__()\n",
    "        self.file=pd.read_csv(file_name)\n",
    "        self.text_data=Load_data(tokenizer,file_path=file_name)\n",
    "        self.use_ip=use_ip\n",
    "    def __getitem__(self, index):\n",
    "        batch=self.text_data[index]\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                'input_ids': batch[0].unsqueeze(0),\n",
    "                'attention_mask': batch[1].unsqueeze(0),\n",
    "                'token_type_ids':batch[2].unsqueeze(0)\n",
    "            }\n",
    "            _,pool_outputs = model(**inputs,return_dict=False)\n",
    "            text_feature=pool_outputs.squeeze()\n",
    "        if self.use_ip:\n",
    "            ip_feature=torch.tensor(self.file.iloc[index,3:6].to_numpy(dtype=float))\n",
    "        url_feature=torch.tensor(self.file.iloc[index,6:].to_numpy(dtype=float))\n",
    "        if self.use_ip:\n",
    "            feature=torch.concat([text_feature,url_feature,ip_feature],dim=-1)\n",
    "        else:\n",
    "            feature=torch.concat([text_feature,url_feature],dim=-1)\n",
    "        url=self.file.iloc[index,0]\n",
    "        return url,feature\n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "print(\"-----æ•°æ®ç±»åŠ è½½å®Œæ¯•-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----æ•°æ®åŠ è½½å®Œæ¯•-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YZY/opt/anaconda3/envs/pytorch_cpu/lib/python3.10/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test=url_data(file_name='./test/ip_encode_display.csv',use_ip=True)\n",
    "print(\"-----æ•°æ®åŠ è½½å®Œæ¯•-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----æ•°æ®é¢„æµ‹å®Œæ¯•-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data=DataLoader(test,batch_size=32)\n",
    "cls=hierarchy_cls(use_ip=True)\n",
    "url,ft=test[0]\n",
    "url_col=[]\n",
    "label=[]\n",
    "for url,ft in tqdm(data):\n",
    "    url_col+=list(url)\n",
    "    pred=cls.predict(torch.tensor(ft.numpy(),dtype=torch.float))\n",
    "    label+=list(pred)\n",
    "    \n",
    "url_csv=pd.Series(url_col)\n",
    "label_csv=pd.Series(label)\n",
    "prediction=pd.concat([url_csv,label_csv],axis=1)\n",
    "prediction.columns=['url','label']\n",
    "prediction.to_csv('./prediction.csv',index=None)\n",
    "print(\"-----æ•°æ®é¢„æµ‹å®Œæ¯•-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
